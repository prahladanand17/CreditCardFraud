{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Data\n",
    "\n",
    "data = pd.read_csv('.../input/creditcard.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a130eb978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Data\n",
    "class_count = pd.value_counts(data['Class'], sort = 'True').sort_index()\n",
    "class_count.plot(kind = 'bar')\n",
    "\n",
    "plt.title(\"Fraud Histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...              V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794        ...        -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974        ...        -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643        ...         0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952        ...        -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074        ...        -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \\\n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "\n",
       "   normalizedAmount  \n",
       "0          0.244964  \n",
       "1         -0.342475  \n",
       "2          1.160686  \n",
       "3          0.140534  \n",
       "4         -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "scale = preprocessing.StandardScaler()\n",
    "data['normalizedAmount'] = scale.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data = data.drop(['Time', 'Amount'], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning X and Y\n",
    "\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "Y = data.loc[:, data.columns == 'Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of and Indices of Data Points in Minority Class (Class == 1)\n",
    "fraud_count = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "\n",
    "#Indices of Majority Class\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "#Picking Random Indices from Majority Class Indices (n = # of Fraud Points)\n",
    "random_normal_indices = np.random.choice(normal_indices,fraud_count,replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "#Combining the two to create Undersampled Dataset\n",
    "undersampled_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "undersampled_data = data.loc[undersampled_indices, :]\n",
    "\n",
    "#Assigning X and Y for Undersampled Data Set\n",
    "X_under = undersampled_data.loc[:, undersampled_data.columns != 'Class']\n",
    "Y_under = undersampled_data.loc[:, undersampled_data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAETCAYAAAAs4pGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a130eb198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting New UnderSampled Data\n",
    "class_count_undersample = pd.value_counts(undersampled_data['Class'], sort = 'True').sort_index()\n",
    "class_count_undersample.plot(kind = 'bar')\n",
    "\n",
    "plt.title(\"Fraud Histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    }
   ],
   "source": [
    "#Splitting Data into Train and Test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "X_train_under, X_test_under, Y_train_under, Y_test_under = train_test_split(X_under, Y_under, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_under))\n",
    "print(\"Number transactions test dataset: \", len(X_test_under))\n",
    "print(\"Total number of transactions: \", len(X_train_under)+len(X_test_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143   6]\n",
      " [ 11 136]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.94       149\n",
      "          1       0.96      0.93      0.94       147\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anprahlad/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Creating Multi-Layered Perceptron (UnderSampled Data)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (28,28,28), activation = 'relu', learning_rate_init = 0.01, solver = 'adam')\n",
    "\n",
    "#Fitting Data\n",
    "mlp.fit(X_train_under, Y_train_under)\n",
    "\n",
    "#Prediction\n",
    "prediction = mlp.predict(X_test_under)\n",
    "\n",
    "#Confusion Matrix and Classification Report\n",
    "print(confusion_matrix(Y_test_under, prediction))\n",
    "print(classification_report(Y_test_under, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anprahlad/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85270    26]\n",
      " [   30   117]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.82      0.80      0.81       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating Multi-Layered Perceptron (Skewed Data)\n",
    "\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes = (28,28,28), activation = 'relu', learning_rate_init = 0.01, solver = 'adam')\n",
    "\n",
    "#Fitting Data\n",
    "mlp2.fit(X_train, Y_train)\n",
    "\n",
    "#Prediction\n",
    "prediction2 = mlp2.predict(X_test)\n",
    "\n",
    "#Confusion Matrix and Classification Report\n",
    "print(confusion_matrix(Y_test, prediction2))\n",
    "print(classification_report(Y_test, prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anprahlad/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80688  4608]\n",
      " [    6   141]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     85296\n",
      "          1       0.03      0.96      0.06       147\n",
      "\n",
      "avg / total       1.00      0.95      0.97     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating Multi-Layered Perceptron (Whole Data)\n",
    "\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes = (28,28,28), activation = 'relu', learning_rate_init = 0.01, solver = 'adam')\n",
    "\n",
    "#Fitting Data\n",
    "mlp3.fit(X_train_under, Y_train_under)\n",
    "\n",
    "#Prediction\n",
    "prediction3= mlp.predict(X_test)\n",
    "\n",
    "#Confusion Matrix and Classification Report\n",
    "print(confusion_matrix(Y_test, prediction3))\n",
    "print(classification_report(Y_test, prediction3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
